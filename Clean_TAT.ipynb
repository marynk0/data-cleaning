{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8f0a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_sep = pd.read_csv(\"G:\\\\Geo Spartial Analysis\\\\tat_sep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96556b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tat_df.columns:\n",
    "    print(f'{col}: {tat_df[col].dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db318f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Convert 'departure_time' to datetime\n",
    "tat_df['Depature_Time'] = pd.to_datetime(tat_df['Depature_Time'], format='%H:%M:%S')\n",
    "\n",
    "# Filter rows where departure time is past 6:00:00\n",
    "past_tat_df = tat_df[tat_df['Depature_Time'].dt.time > pd.to_datetime('06:00:00', format='%H:%M:%S').time()]\n",
    "\n",
    "# Filter rows where departure time is before 6:00:00\n",
    "before_tat_df = tat_df[tat_df['Depature_Time'].dt.time < pd.to_datetime('06:00:00', format='%H:%M:%S').time()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_tat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e43a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_tat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6405af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = r'G:\\NEW\\before_tat_data.csv'\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "before_tat_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbb0777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = r'G:\\NEW\\past_tat_data.csv'\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "past_tat_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fd7e7f",
   "metadata": {},
   "source": [
    "Clean 2nd dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82493039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_sep = pd.read_csv(\"G:\\\\Geo Spartial Analysis\\\\tat_sep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d765c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Branch Trucknumber CAPACITY        Drivers Tripchart created  \\\n",
      "0  NAKURU    KDK 183Z      10T  Daniel Mugiri        09/01/2023   \n",
      "1  NAKURU    KCN 429Z      10T    Benard Rono        31/08/2023   \n",
      "2  NAKURU    KCF 048R      10T   James Ndungu        09/01/2023   \n",
      "3  NAKURU    KDH 305W      10T    Edwin Ngeno        09/01/2023   \n",
      "4  NAKURU    KCT 231T      10T    John Kimani        31/08/2023   \n",
      "\n",
      "  Trip chart No.              Route         Departure No. of customers  \\\n",
      "0          19064   NAKURU - MARALAL  09/01/2023 05:27                5   \n",
      "1          19043  NAKURU - NARUSURA  09/01/2023 05:52               30   \n",
      "2          19060   NAKURU - ELDORET  09/01/2023 06:00               14   \n",
      "3            NaN     NAKURU-KERICHO  09/01/2023 06:00               20   \n",
      "4          19056     NAKURU-KERICHO  09/01/2023 05:55               18   \n",
      "\n",
      "               Time     kms            Time.1     Kms Totak Kms   tonnage  \\\n",
      "0  09/01/2023 08:31  107.11  09/01/2023 20:18  331.96    491.19   8896.76   \n",
      "1  09/01/2023 08:12   72.06  09/02/2023 11:06  247.64    511.32       NaN   \n",
      "2  09/01/2023 07:24   39.89  09/02/2023 12:23  412.34     527.1   9197.94   \n",
      "3  09/01/2023 08:14   60.54  09/02/2023 15:13  455.51    603.85  10058.78   \n",
      "4  09/01/2023 07:15   39.75  09/01/2023 19:30  405.78    445.52    9706.4   \n",
      "\n",
      "            Arrival  \n",
      "0  09/01/2023 22:12  \n",
      "1  09/02/2023 17:43  \n",
      "2  09/02/2023 14:29  \n",
      "3  09/02/2023 19:55  \n",
      "4  09/02/2023 10:11  \n"
     ]
    }
   ],
   "source": [
    "print(df_sep.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc4339b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "departure_dtype = df_sep['Departure'].dtype\n",
    "print(departure_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b017e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_custom_datetime(datetime_str):\n",
    "    # Check if the string contains only date and hour:minute (without seconds)\n",
    "    if datetime_str.count(':') == 1:\n",
    "        datetime_str += ':00'  # Add seconds as '00' if missing\n",
    "    \n",
    "    # Use pd.to_datetime to parse the datetime string\n",
    "    return pd.to_datetime(datetime_str, format='%m/%d/%Y %H:%M:%S', errors='coerce')\n",
    "\n",
    "# Assuming your DataFrame is named df_sep\n",
    "df_sep['Departure'] = df_sep['Departure'].astype(str)\n",
    "df_sep['Departure'] = df_sep['Departure'].str.replace('20223', '2023').str.replace('20203', '2023')\n",
    "\n",
    "# Apply the custom datetime parsing function to the 'Departure' column\n",
    "df_sep['Departure'] = df_sep['Departure'].apply(parse_custom_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "858c0730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "departure_dtype = df_sep['Departure'].dtype\n",
    "print(departure_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be74757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       09/01/2023 22:12\n",
      "1       09/02/2023 17:43\n",
      "2       09/02/2023 14:29\n",
      "3       09/02/2023 19:55\n",
      "4       09/02/2023 10:11\n",
      "              ...       \n",
      "1431      9/30/2023 9:35\n",
      "1432     9/30/2023 13:43\n",
      "1433     9/30/2023 15:32\n",
      "1434     9/30/2023 17:32\n",
      "1435     9/30/2023 18:30\n",
      "Name: Arrival, Length: 1436, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_sep['Arrival'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adeab7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "#boolean mask to identify rows with the value \"System error\"\n",
    "mask = (df_sep == 'System error').any(axis=1)\n",
    "\n",
    "#mask to filter the DataFrame and keep only rows without \"System error\"\n",
    "df_sep = df_sep[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfae0e11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_custom_datetime(datetime_str):\n",
    "    # Check if the string contains only date and hour:minute (without seconds)\n",
    "    if datetime_str.count(':') == 1:\n",
    "        datetime_str += ':00'  # Add seconds as '00' if missing\n",
    "    \n",
    "    # Use pd.to_datetime to parse the datetime string\n",
    "    return pd.to_datetime(datetime_str, format='%m/%d/%Y %H:%M:%S', errors='coerce')\n",
    "\n",
    "# Assuming your DataFrame is named df_sep\n",
    "df_sep['Arrival'] = df_sep['Arrival'].astype(str)\n",
    "df_sep['Arrival'] = df_sep['Arrival'].str.replace('Market', '').replace('Pending', '').replace('PM', '')\n",
    "\n",
    "# Apply the custom datetime parsing function to the 'Arrival' column\n",
    "df_sep['Arrival'] = df_sep['Arrival'].apply(parse_custom_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fb995f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "departure_dtype = df_sep['Arrival'].dtype\n",
    "print(departure_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9558eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10T,5T,14T,28T,Tuktuk,Van\n",
    "#Clean the Capacity Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef299354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        10T\n",
      "1        10T\n",
      "2        10T\n",
      "3        10T\n",
      "4        10T\n",
      "        ... \n",
      "1431    0.5T\n",
      "1432    0.5T\n",
      "1433    0.5T\n",
      "1434    0.5T\n",
      "1435    0.5T\n",
      "Name: CAPACITY, Length: 1434, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_sep['CAPACITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89778c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10T' '5T' '14T' '28T' '0.5T' '10 Tonner' '5 Tonner' '10TONER' '0.5TONER'\n",
      " '5TONER']\n"
     ]
    }
   ],
   "source": [
    "unique_values = df_sep['CAPACITY'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd61d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_mapping = {\n",
    "    '10 Tonner': '10T',\n",
    "    '5 Tonner': '5T',\n",
    "    '10TONER': '10T',\n",
    "    '0.5TONER': '5T',\n",
    "    '5TONER': '5T',\n",
    "    '0.5T' :'5T'\n",
    "}\n",
    "\n",
    "# Use the replace method with the dictionary to update the 'CAPACITY' column\n",
    "df_sep['CAPACITY'] = df_sep['CAPACITY'].replace(capacity_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef42ad34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10T' '5T' '14T' '28T']\n"
     ]
    }
   ],
   "source": [
    "unique_values = df_sep['CAPACITY'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf0c8fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to the CSV file\n",
    "df_sep.to_csv(\"G:\\\\Geo Spartial Analysis\\\\date_tat_sep.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8324c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
